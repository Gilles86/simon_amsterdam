{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import nipype.pipeline.engine as pe\r\n",
      "import nipype.interfaces.io as nio\r\n",
      "import nipype.interfaces.utility as util\r\n",
      "from nipype.workflows.fmri.fsl.estimate import create_modelfit_workflow, create_fixed_effects_flow\r\n",
      "from gilles_workflows import create_fdr_threshold_workflow\r\n",
      "\r\n",
      "meta_workflow = pe.Workflow(name='fit_aron3', base_dir='/home/gdholla1/workflow_folders/')\r\n",
      "\r\n",
      "\r\n",
      "modelfit_workflow = create_modelfit_workflow(name='fit_aron_masked')\r\n",
      "\r\n",
      "modelfit_workflow.base_dir = '/home/gdholla1/workflow_folders/'\r\n",
      "modelfit_workflow.inputs.inputspec.bases = {'dgamma': {'derivs': True}}\r\n",
      "modelfit_workflow.inputs.inputspec.contrasts = [('task', 'T', ['task'], [1.0])]\r\n",
      "modelfit_workflow.inputs.inputspec.film_threshold = 1000\r\n",
      "modelfit_workflow.inputs.inputspec.interscan_interval = 2.0\r\n",
      "modelfit_workflow.inputs.inputspec.model_serial_correlations = True\r\n",
      "\r\n",
      "modelfit_workflow.inputs.inputspec.contrasts = [('stop_failed > go', 'T', ['stop_failed', 'go'], [1.0, -1.0]),\r\n",
      "                                       ('go > stop_failed', 'T', ['go', 'stop_failed'], [1.0, -1.0]),\r\n",
      "                                       ('stop_failed > stop_inhibit', 'T', ['stop_failed', 'stop_inhibit'], [1.0, -1.0]),\r\n",
      "                                       ('stop_inhibit > stop_failed', 'T', ['stop_inhibit', 'stop_failed'], [1.0, -1.0]),\r\n",
      "                                       ('stop_inhibit > go', 'T', ['stop_inhibit', 'go'], [1.0, -1.0]),\r\n",
      "                                       ('go > stop_inhibit', 'T', ['go', 'stop_inhibit'], [1.0, -1.0]),\r\n",
      "                                       ('go > baseline', 'T', ['go'], [1.0]),\r\n",
      "                                       ('stop_inhibit > baseline', 'T', ['stop_inhibit'], [1.0]),\r\n",
      "                                       ('stop_failed > baseline', 'T', ['stop_failed'], [1.0])]\r\n",
      "\r\n",
      "\r\n",
      "identity = pe.Node(util.IdentityInterface(fields=['subject_id', 'run']),\r\n",
      "                                  name='identity')\r\n",
      "\r\n",
      "#sids = ['KCAT', 'WSFT', 'WW2T', 'TS6T', 'FMFT', 'HCBT', 'PF5T', 'LV2T', 'UM2T', 'MRCT', 'RSIT', 'KP6T', 'NM3T', 'BI3T', 'SC1T', 'SPGT', 'ZK4T', 'GAIT', 'DA9T', 'VL1T'] \r\n",
      "sids = ['KCAT', 'WSFT', 'WW2T', 'TS6T', 'FMFT', 'HCBT', 'PF5T', 'LV2T', 'UM2T', 'MRCT', 'RSIT', 'KP6T', 'NM3T', 'BI3T', 'SC1T', 'SPGT', 'ZK4T', 'GAIT', 'VL1T'] \r\n",
      "#sids = sids[-6:]\r\n",
      "print len(sids)\r\n",
      "#sids = ['VL1T', 'GAIT', 'ZK4T', ]\r\n",
      "\r\n",
      "identity.iterables = [('subject_id', sids)]\r\n",
      "identity.inputs.run = [1,2,3]\r\n",
      "\r\n",
      "templates = {'epi':'/home/gdholla1/data/stop3/preprocessed/motion_regressors_filtered_files/_subject_id_{subject_id}/_fwhm_{fwhm}/_addmean*/run*.nii.gz',\r\n",
      "        #'epi':'/home/gdholla1/data/stop3/preprocessed/feat_preprocess/{preprocess}/_subject_id_{subject_id}/_fwhm_{fwhm}/_addmean*/run*.nii.gz',\r\n",
      "                     'mask':'/home/gdholla1/data/stop3/preprocessed/feat_preprocess/mask/_subject_id_{subject_id}/_fwhm_{fwhm}/_dilatemask0/run1*.nii.gz'}\r\n",
      "\r\n",
      "selector = pe.Node(nio.SelectFiles(templates), name='selector')\r\n",
      "#selector.iterables = [('fwhm', [0.0, 1.5, 5.0])]\r\n",
      "selector.iterables = [('fwhm', [1.5])]\r\n",
      "\r\n",
      "def get_session_info(subject_id, run, shift=0):\r\n",
      "    import pandas\r\n",
      "    import numpy as np\r\n",
      "    from nipype.interfaces.base import Bunch\r\n",
      "    \r\n",
      "    df = pandas.read_pickle('/home/gdholla1/data/stop3/behavior/all_data.pandas')\r\n",
      "    \r\n",
      "    df = df[(df.subject_id == subject_id) & (df.run == run)]\r\n",
      "    df['onset'] += shift\r\n",
      "    \r\n",
      "    onsets_task = df['onset'].tolist()\r\n",
      "    onsets_stop_inhibit = df[df.stop & df.succesful_stop]['onset'].tolist()\r\n",
      "    onsets_stop_failed = df[df.stop & (df.succesful_stop == 0)]['onset'].tolist()\r\n",
      "    onsets_go = df[~df.stop]['onset'].tolist()\r\n",
      "\r\n",
      "    info = Bunch(conditions=['go',\r\n",
      "                          'stop_inhibit',\r\n",
      "                          'stop_failed',],\r\n",
      "              onsets=[onsets_go,\r\n",
      "                      onsets_stop_inhibit,\r\n",
      "                      onsets_stop_failed,],\r\n",
      "              durations=[[1]] * 3)\r\n",
      "    \r\n",
      "    return info\r\n",
      "\r\n",
      "\r\n",
      "session_info_getter = pe.MapNode(util.Function(function=get_session_info,\r\n",
      "                                     input_names=['subject_id', 'run', 'shift'],\r\n",
      "                                     output_names=['session_info']),\r\n",
      "                       iterfield=['run'],\r\n",
      "                       name='session_info_getter')\r\n",
      "session_info_getter.iterables = [('shift', [-2.0])]\r\n",
      "\r\n",
      "\r\n",
      "meta_workflow.connect([(identity, selector,\r\n",
      "                   [('subject_id', 'subject_id'),\r\n",
      "                    ('run', 'run')])])\r\n",
      "\r\n",
      "meta_workflow.connect([(identity, session_info_getter,\r\n",
      "                   [('subject_id', 'subject_id'),\r\n",
      "                    ('run', 'run')])])\r\n",
      "\r\n",
      "from nipype.algorithms.modelgen import SpecifyModel\r\n",
      "from nipype.interfaces import fsl\r\n",
      "\r\n",
      "specifymodel = pe.Node(SpecifyModel(), name='specifymodel')\r\n",
      "specifymodel.inputs.input_units = 'secs'\r\n",
      "specifymodel.inputs.time_repetition = 2\r\n",
      "specifymodel.inputs.high_pass_filter_cutoff = 128. / (2. * 2.)\r\n",
      "\r\n",
      "\r\n",
      "meta_workflow.connect([\r\n",
      "                  (selector, modelfit_workflow,\r\n",
      "                   [('epi', 'inputspec.functional_data')]),\r\n",
      "                  (session_info_getter, specifymodel,\r\n",
      "                   [('session_info', 'subject_info'),]),\r\n",
      "                  (selector, specifymodel,\r\n",
      "                  [('epi', 'functional_runs'),]),\r\n",
      "                  (specifymodel, modelfit_workflow,\r\n",
      "                   [('session_info', 'inputspec.session_info'),])\r\n",
      "                  ])\r\n",
      "\r\n",
      "fixedfx = create_fixed_effects_flow()\r\n",
      "\r\n",
      "meta_workflow.connect(selector, 'mask', fixedfx, 'flameo.mask_file')\r\n",
      "\r\n",
      "def num_copes(files):\r\n",
      "    return len(files)\r\n",
      "\r\n",
      "def transpose_copes(copes):    \r\n",
      "    import numpy as np\r\n",
      "    return np.array(copes).T.tolist()\r\n",
      "\r\n",
      "meta_workflow.connect([(modelfit_workflow, fixedfx,\r\n",
      "                   [(('outputspec.copes', transpose_copes), 'inputspec.copes'),\r\n",
      "                    (('outputspec.varcopes', transpose_copes), 'inputspec.varcopes'),\r\n",
      "                    ('outputspec.dof_file', 'inputspec.dof_files'),\r\n",
      "                    (('outputspec.copes', num_copes), 'l2model.num_copes')])])\r\n",
      "\r\n",
      "\r\n",
      "ztopval = pe.MapNode(interface=fsl.ImageMaths(op_string='-ztop',\r\n",
      "                                              suffix='_pval'),\r\n",
      "                     nested=True,\r\n",
      "                     iterfield=['in_file'],\r\n",
      "                     name='ztop',)\r\n",
      "\r\n",
      "fdr_workflow = create_fdr_threshold_workflow()\r\n",
      "\r\n",
      "meta_workflow.connect([\r\n",
      "                  (fixedfx, ztopval,\r\n",
      "                   [('outputspec.zstats', 'in_file'),]),\r\n",
      "                  (fixedfx, fdr_workflow,\r\n",
      "                   [('outputspec.zstats', 'inputspec.z_stats'),]),\r\n",
      "                  (ztopval, fdr_workflow,\r\n",
      "                   [('out_file', 'inputspec.p_values'),]),\r\n",
      "                  (selector, fdr_workflow,\r\n",
      "                   [('mask', 'inputspec.mask'),]),\r\n",
      "                  ])\r\n",
      "\r\n",
      "ds = pe.Node(nio.DataSink(), name='datasink')\r\n",
      "ds.inputs.base_directory = '/home/gdholla1/data/stop3/fit_aron_glm'\r\n",
      "ds.inputs.regexp_substitutions = [('/_flameo([0-9]+)/([a-z0-9_]+).nii.gz', '/\\\\2_contrast\\\\1.nii.gz'),\r\n",
      "        ('/_masker([0-9]+)/zstat1_masked.nii.gz', '/thresholded_zstat_contrast\\\\1.nii.gz'),]\r\n",
      "\r\n",
      "meta_workflow.connect(fixedfx, 'outputspec.zstats', ds, 'zstats')\r\n",
      "meta_workflow.connect(fixedfx, 'outputspec.copes', ds, 'level2_copes')\r\n",
      "meta_workflow.connect(fixedfx, 'outputspec.varcopes', ds, 'level2_varcopes')\r\n",
      "meta_workflow.connect(fixedfx, 'flameo.tdof', ds, 'level2_tdof')\r\n",
      "meta_workflow.connect(fdr_workflow, 'outputspec.thresholded_z_stats', ds, 'thresholded_z_stats')\r\n",
      "\r\n",
      "#meta_workflow.run()\r\n",
      "meta_workflow.run(plugin='MultiProc', plugin_args={'n_procs':8})\r\n"
     ]
    }
   ],
   "source": [
    "!cat /home/gdholla1/projects/stop3/fit_aron_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.io as nio\n",
    "import nipype.interfaces.utility as util\n",
    "from nipype.workflows.fmri.fsl.estimate import create_modelfit_workflow, create_fixed_effects_flow\n",
    "from gilles_workflows import create_fdr_threshold_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "templates = {'epi':'/home/gdholla1/data/simon_amsterdam/preprocessing_results/highpassed_files/_subject_id_{subject_id}/_fwhm_5.0/_addmean*/run{run}_dtype_mcf_mask_smooth_mask_gms_tempfilt_maths.nii.gz',\n",
    "            'mask':'/home/gdholla1/data/simon_amsterdam/preprocessing_results/mask/_subject_id_{subject_id}/_fwhm_5.0/_dilatemask0/run1_dtype_mcf_bet_thresh_dil.nii.gz'}\n",
    "\n",
    "selector = pe.MapNode(nio.SelectFiles(templates), iterfield=['run'], name='selector')\n",
    "selector.inputs.run = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Trial</th>\n",
       "      <th>Event Type</th>\n",
       "      <th>Code</th>\n",
       "      <th>Time</th>\n",
       "      <th>TTime</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Uncertainty.1</th>\n",
       "      <th>ReqTime</th>\n",
       "      <th>...</th>\n",
       "      <th>modality</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>stimulus_location</th>\n",
       "      <th>response</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>correct</th>\n",
       "      <th>congruent</th>\n",
       "      <th>congruency</th>\n",
       "      <th>block_onset</th>\n",
       "      <th>onset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>3</td>\n",
       "      <td>Picture</td>\n",
       "      <td>redfix</td>\n",
       "      <td>611188</td>\n",
       "      <td>3066</td>\n",
       "      <td>2</td>\n",
       "      <td>3067</td>\n",
       "      <td>3</td>\n",
       "      <td>2960</td>\n",
       "      <td>...</td>\n",
       "      <td>Visual</td>\n",
       "      <td>face</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>incongruent</td>\n",
       "      <td>608086</td>\n",
       "      <td>0.3102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>5</td>\n",
       "      <td>Picture</td>\n",
       "      <td>redfix</td>\n",
       "      <td>651721</td>\n",
       "      <td>3067</td>\n",
       "      <td>1</td>\n",
       "      <td>3067</td>\n",
       "      <td>2</td>\n",
       "      <td>2960</td>\n",
       "      <td>...</td>\n",
       "      <td>Visual</td>\n",
       "      <td>face</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>incongruent</td>\n",
       "      <td>608086</td>\n",
       "      <td>4.3635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001</td>\n",
       "      <td>7</td>\n",
       "      <td>Picture</td>\n",
       "      <td>redfix</td>\n",
       "      <td>697187</td>\n",
       "      <td>3067</td>\n",
       "      <td>1</td>\n",
       "      <td>3066</td>\n",
       "      <td>3</td>\n",
       "      <td>2960</td>\n",
       "      <td>...</td>\n",
       "      <td>Visual</td>\n",
       "      <td>house</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>congruent</td>\n",
       "      <td>608086</td>\n",
       "      <td>8.9101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001</td>\n",
       "      <td>9</td>\n",
       "      <td>Picture</td>\n",
       "      <td>redfix</td>\n",
       "      <td>747719</td>\n",
       "      <td>3066</td>\n",
       "      <td>1</td>\n",
       "      <td>3067</td>\n",
       "      <td>2</td>\n",
       "      <td>2960</td>\n",
       "      <td>...</td>\n",
       "      <td>Visual</td>\n",
       "      <td>face</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>congruent</td>\n",
       "      <td>608086</td>\n",
       "      <td>13.9633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001</td>\n",
       "      <td>11</td>\n",
       "      <td>Picture</td>\n",
       "      <td>redfix</td>\n",
       "      <td>803185</td>\n",
       "      <td>3067</td>\n",
       "      <td>1</td>\n",
       "      <td>3067</td>\n",
       "      <td>2</td>\n",
       "      <td>2960</td>\n",
       "      <td>...</td>\n",
       "      <td>Visual</td>\n",
       "      <td>face</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>incongruent</td>\n",
       "      <td>608086</td>\n",
       "      <td>19.5099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject Trial Event Type    Code    Time TTime Uncertainty Duration  \\\n",
       "0     001     3    Picture  redfix  611188  3066           2     3067   \n",
       "1     001     5    Picture  redfix  651721  3067           1     3067   \n",
       "2     001     7    Picture  redfix  697187  3067           1     3066   \n",
       "3     001     9    Picture  redfix  747719  3066           1     3067   \n",
       "4     001    11    Picture  redfix  803185  3067           1     3067   \n",
       "\n",
       "  Uncertainty.1 ReqTime   ...    modality stimulus  stimulus_location  \\\n",
       "0             3    2960   ...      Visual     face              right   \n",
       "1             2    2960   ...      Visual     face              right   \n",
       "2             3    2960   ...      Visual    house              right   \n",
       "3             2    2960   ...      Visual     face               left   \n",
       "4             2    2960   ...      Visual     face              right   \n",
       "\n",
       "   response  correct_answer  correct  congruent   congruency block_onset  \\\n",
       "0      left            left     True      False  incongruent      608086   \n",
       "1      left            left     True      False  incongruent      608086   \n",
       "2     right           right     True       True    congruent      608086   \n",
       "3      left            left     True       True    congruent      608086   \n",
       "4      left            left     True      False  incongruent      608086   \n",
       "\n",
       "     onset  \n",
       "0   0.3102  \n",
       "1   4.3635  \n",
       "2   8.9101  \n",
       "3  13.9633  \n",
       "4  19.5099  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.read_pickle('/home/gdholla1/data/simon_amsterdam/behavior/all_data.pandas')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject_id= 1\n",
    "run = 7\n",
    "shift = 0\n",
    "\n",
    "df = pandas.read_pickle('/home/gdholla1/data/simon_amsterdam/behavior/all_data.pandas')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.RT == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_session_info(subject_id, run, shift=0):\n",
    "    import pandas\n",
    "    import numpy as np\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    \n",
    "    df = pandas.read_pickle('/home/gdholla1/data/simon_amsterdam/behavior/all_data.pandas')\n",
    "\n",
    "    df = df[(df.subject_id == subject_id) & (df.run == run)]\n",
    "    df['onset'] += shift\n",
    "\n",
    "    onsets_left_congruent = df[(df.stimulus_location == 'left') & (df.congruency == 'congruent')].onset.tolist()\n",
    "    onsets_left_incongruent = df[(df.stimulus_location == 'left') & (df.congruency == 'incongruent')].onset.tolist()\n",
    "\n",
    "    onsets_right_congruent = df[(df.stimulus_location == 'right') & (df.congruency == 'congruent')].onset.tolist()\n",
    "    onsets_right_incongruent = df[(df.stimulus_location == 'right') & (df.congruency == 'incongruent')].onset.tolist()\n",
    "\n",
    "    onsets_slow = df[df.slow == 'slow'].onset.tolist()\n",
    "    onsets_error = df[df.correct == False].onset.tolist()\n",
    "\n",
    "    info = Bunch(conditions=['left_congruent',\n",
    "                          'left_incongruent',\n",
    "                          'right_congruent',\n",
    "                            'right_incongruent',\n",
    "                            'slow',\n",
    "                            'error'],\n",
    "              onsets=[onsets_left_congruent,\n",
    "                      onsets_left_incongruent,\n",
    "                      onsets_right_congruent,\n",
    "                      onsets_right_incongruent,\n",
    "                      onsets_slow,\n",
    "                      onsets_error],\n",
    "              durations=[[1]] * 6)\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-d261a1282a6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[0mmeta_workflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfdr_workflow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'outputspec.thresholded_z_stats'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'thresholded_z_stats'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m \u001b[0mmeta_workflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;31m# meta_workflow.run(plugin='MultiProc', plugin_args={'n_procs':8})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gdholla1/git_projects/nipype/nipype/pipeline/engine/workflows.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'execution'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_report'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'execution'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'write_provenance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gdholla1/git_projects/nipype/nipype/pipeline/plugins/linear.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'exception'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/gdholla1/git_projects/nipype/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[1;34m(notrun)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"***********************************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[0;32m     94\u001b[0m                             'Check log for details'))\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "meta_workflow = pe.Workflow(name='fit_puck', base_dir='/home/gdholla1/workflow_folders/')\n",
    "\n",
    "\n",
    "modelfit_workflow = create_modelfit_workflow(name='modelfit_puck')\n",
    "\n",
    "modelfit_workflow.base_dir = '/home/gdholla1/workflow_folders/'\n",
    "modelfit_workflow.inputs.inputspec.bases = {'dgamma': {'derivs': True}}\n",
    "modelfit_workflow.inputs.inputspec.contrasts = [('task', 'T', ['task'], [1.0])]\n",
    "modelfit_workflow.inputs.inputspec.film_threshold = 1000\n",
    "modelfit_workflow.inputs.inputspec.interscan_interval = 2.5\n",
    "modelfit_workflow.inputs.inputspec.model_serial_correlations = True\n",
    "\n",
    "modelfit_workflow.inputs.inputspec.contrasts = [('incongruent > congruent', 'T', \n",
    "                                                 ['left_incongruent', 'right_incongruent', 'left_congruent', 'right_congruent'], \n",
    "                                                 [1.0, 1.0, -1.0, -1.0]),\n",
    "                                                ('congruent > incongruent', 'T',\n",
    "                                                 ['left_congruent', 'right_congruent', 'left_incongruent', 'right_incongruent'], \n",
    "                                                 [1.0, 1.0, -1.0, -1.0]),\n",
    "                                                 ('face > house', 'T',\n",
    "                                                 ['left_congruent', 'right_incongruent', 'left_incongruent', 'right_congruent'], \n",
    "                                                 [1.0, 1.0, -1.0, -1.0]), \n",
    "                                                 ('house > face', 'T',\n",
    "                                                 ['left_incongruent', 'right_congruent', 'left_congruent', 'right_incongruent'], \n",
    "                                                 [1.0, 1.0, -1.0, -1.0]),                                                 \n",
    "                                                 ('congruent left (face) > congruent right (house)', 'T',\n",
    "                                                 ['left_congruent', 'right_congruent'],\n",
    "                                                 [1.0, -1.0]),\n",
    "                                                 ('incongruent left (house) > incongruent right (face)', 'T',\n",
    "                                                 ['left_incongruent', 'right_incongruent'],\n",
    "                                                 [1.0, -1.0]),\n",
    "                                                 ('congruent left (face) > incongruent right (face)', 'T',\n",
    "                                                 ['left_incongruent', 'right_incongruent'],\n",
    "                                                 [1.0, -1.0]),\n",
    "                                                 ('congruent right (house) > incongruent left (house)', 'T',\n",
    "                                                 ['right_incongruent', 'left_incongruent'],\n",
    "                                                 [1.0, -1.0]),\n",
    "                                                 ('error > baseline', 'T',\n",
    "                                                 ['error'],\n",
    "                                                 [1.0]),\n",
    "                                                 ('slow > baseline', 'T',\n",
    "                                                 ['slow'],\n",
    "                                                 [1.0])                                               ]\n",
    "\n",
    "\n",
    "identity = pe.Node(util.IdentityInterface(fields=['subject_id', 'run']),\n",
    "                                  name='identity')\n",
    "\n",
    "identity.iterables = [('subject_id', [1])]\n",
    "identity.inputs.run = [1,2,3, 4]\n",
    "\n",
    "templates = {'epi':'/home/gdholla1/data/simon_amsterdam/preprocessing_results/highpassed_files/_subject_id_{subject_id}/_fwhm_5.0/_addmean*/run{run}_dtype_mcf_mask_smooth_mask_gms_tempfilt_maths.nii.gz',\n",
    "            'mask':'/home/gdholla1/data/simon_amsterdam/preprocessing_results/mask/_subject_id_{subject_id}/_fwhm_5.0/_dilatemask0/run1_dtype_mcf_bet_thresh_dil.nii.gz'}\n",
    "\n",
    "selector = pe.MapNode(nio.SelectFiles(templates), iterfield=['run'], name='selector')\n",
    "\n",
    "def get_session_info(subject_id, run, shift=0):\n",
    "    import pandas\n",
    "    import numpy as np\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    \n",
    "    df = pandas.read_pickle('/home/gdholla1/data/simon_amsterdam/behavior/all_data.pandas')\n",
    "\n",
    "    df = df[(df.subject_id == subject_id) & (df.run == run)]\n",
    "    df['onset'] += shift\n",
    "\n",
    "    onsets_left_congruent = df[(df.stimulus_location == 'left') & (df.congruency == 'congruent')].onset.tolist()\n",
    "    onsets_left_incongruent = df[(df.stimulus_location == 'left') & (df.congruency == 'incongruent')].onset.tolist()\n",
    "\n",
    "    onsets_right_congruent = df[(df.stimulus_location == 'right') & (df.congruency == 'congruent')].onset.tolist()\n",
    "    onsets_right_incongruent = df[(df.stimulus_location == 'right') & (df.congruency == 'incongruent')].onset.tolist()\n",
    "\n",
    "    onsets_slow = df[df.slow == 'slow'].onset.tolist()\n",
    "    onsets_error = df[df.correct == False].onset.tolist()\n",
    "\n",
    "    info = Bunch(conditions=['left_congruent',\n",
    "                          'left_incongruent',\n",
    "                          'right_congruent',\n",
    "                            'right_incongruent',\n",
    "                            'slow',\n",
    "                            'error'],\n",
    "              onsets=[onsets_left_congruent,\n",
    "                      onsets_left_incongruent,\n",
    "                      onsets_right_congruent,\n",
    "                      onsets_right_incongruent,\n",
    "                      onsets_slow,\n",
    "                      onsets_error],\n",
    "              durations=[[1]] * 6)\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "session_info_getter = pe.MapNode(util.Function(function=get_session_info,\n",
    "                                     input_names=['subject_id', 'run', 'shift'],\n",
    "                                     output_names=['session_info']),\n",
    "                       iterfield=['run'],\n",
    "                       name='session_info_getter')\n",
    "session_info_getter.iterables = [('shift', [-2.0])]\n",
    "\n",
    "\n",
    "meta_workflow.connect([(identity, selector,\n",
    "                   [('subject_id', 'subject_id'),\n",
    "                    ('run', 'run')])])\n",
    "\n",
    "meta_workflow.connect([(identity, session_info_getter,\n",
    "                   [('subject_id', 'subject_id'),\n",
    "                    ('run', 'run')])])\n",
    "\n",
    "from nipype.algorithms.modelgen import SpecifyModel\n",
    "from nipype.interfaces import fsl\n",
    "\n",
    "specifymodel = pe.Node(SpecifyModel(), name='specifymodel')\n",
    "specifymodel.inputs.input_units = 'secs'\n",
    "specifymodel.inputs.time_repetition = 2\n",
    "specifymodel.inputs.high_pass_filter_cutoff = 128. / (2. * 2.)\n",
    "\n",
    "\n",
    "meta_workflow.connect([\n",
    "                  (selector, modelfit_workflow,\n",
    "                   [('epi', 'inputspec.functional_data')]),\n",
    "                  (session_info_getter, specifymodel,\n",
    "                   [('session_info', 'subject_info'),]),\n",
    "                  (selector, specifymodel,\n",
    "                  [('epi', 'functional_runs'),]),\n",
    "                  (specifymodel, modelfit_workflow,\n",
    "                   [('session_info', 'inputspec.session_info'),])\n",
    "                  ])\n",
    "\n",
    "fixedfx = create_fixed_effects_flow()\n",
    "\n",
    "meta_workflow.connect(selector, 'mask', fixedfx, 'flameo.mask_file')\n",
    "\n",
    "def num_copes(files):\n",
    "    return len(files)\n",
    "\n",
    "def transpose_copes(copes):    \n",
    "    import numpy as np\n",
    "    return np.array(copes).T.tolist()\n",
    "\n",
    "meta_workflow.connect([(modelfit_workflow, fixedfx,\n",
    "                   [(('outputspec.copes', transpose_copes), 'inputspec.copes'),\n",
    "                    (('outputspec.varcopes', transpose_copes), 'inputspec.varcopes'),\n",
    "                    ('outputspec.dof_file', 'inputspec.dof_files'),\n",
    "                    (('outputspec.copes', num_copes), 'l2model.num_copes')])])\n",
    "\n",
    "\n",
    "ztopval = pe.MapNode(interface=fsl.ImageMaths(op_string='-ztop',\n",
    "                                              suffix='_pval'),\n",
    "                     nested=True,\n",
    "                     iterfield=['in_file'],\n",
    "                     name='ztop',)\n",
    "\n",
    "fdr_workflow = create_fdr_threshold_workflow()\n",
    "\n",
    "meta_workflow.connect([\n",
    "                  (fixedfx, ztopval,\n",
    "                   [('outputspec.zstats', 'in_file'),]),\n",
    "                  (fixedfx, fdr_workflow,\n",
    "                   [('outputspec.zstats', 'inputspec.z_stats'),]),\n",
    "                  (ztopval, fdr_workflow,\n",
    "                   [('out_file', 'inputspec.p_values'),]),\n",
    "                  (selector, fdr_workflow,\n",
    "                   [('mask', 'inputspec.mask'),]),\n",
    "                  ])\n",
    "\n",
    "ds = pe.Node(nio.DataSink(), name='datasink')\n",
    "ds.inputs.base_directory = '/home/gdholla1/data/simon_amsterdam/modelfit_visual'\n",
    "ds.inputs.regexp_substitutions = [('/_flameo([0-9]+)/([a-z0-9_]+).nii.gz', '/\\\\2_contrast\\\\1.nii.gz'),\n",
    "        ('/_masker([0-9]+)/zstat1_masked.nii.gz', '/thresholded_zstat_contrast\\\\1.nii.gz'),]\n",
    "\n",
    "meta_workflow.connect(fixedfx, 'outputspec.zstats', ds, 'zstats')\n",
    "meta_workflow.connect(fixedfx, 'outputspec.copes', ds, 'level2_copes')\n",
    "meta_workflow.connect(fixedfx, 'outputspec.varcopes', ds, 'level2_varcopes')\n",
    "meta_workflow.connect(fixedfx, 'flameo.tdof', ds, 'level2_tdof')\n",
    "meta_workflow.connect(fdr_workflow, 'outputspec.thresholded_z_stats', ds, 'thresholded_z_stats')\n",
    "\n",
    "meta_workflow.run()\n",
    "# meta_workflow.run(plugin='MultiProc', plugin_args={'n_procs':8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
